{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIERS Container BOL Data ETL \n",
    "\n",
    "This notebook builds an ETL pipeline for S&P Global's PIERS data. Data is extracted from CSV files downloaded from the Global Trade Analytics Suite, assigned appropriate datatypes, concatendated into a single dataframe, and loaded to an Apache Parquet file for storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#display settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Transform\n",
    "\n",
    "Read from csv into a pandas dataframe with appropriate dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note for future optimization: build a dictionary of column dtypes and assign within read_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "path = 'data/raw/'\n",
    "#get list of data files, ignoring any hidden files in directory \n",
    "datafiles = [file for file in os.listdir(path) if not file.startswith('.')]\n",
    "#init filenumber\n",
    "filenumber = 1\n",
    "#define new col names\n",
    "import_colnames_dict = {'Weight': 'weight',\n",
    "                        'Weight Unit': 'weight_unit',\n",
    "                        'Quantity': 'qty',\n",
    "                        'Quantity Type': 'qty_type',\n",
    "                        'TEUs': 'teus',\n",
    "                        'Estimated Value': 'value_est',\n",
    "                        'Arrival Date': 'date_arrival',\n",
    "                        'Container Piece Count': 'container_piece_count',\n",
    "                        'Quantity of Commodity Short Description': 'commod_short_desc_qty',\n",
    "                        'Territory of Origin': 'origin_territory',\n",
    "                        'Region of Origin': 'origin_region',\n",
    "                        'Port of Arrival Code': 'arrival_port_code',\n",
    "                        'Port of Arrival': 'arrival_port_name',\n",
    "                        'Port of Departure Code': 'departure_port_code',\n",
    "                        'Port of Departure': 'departure_port_name',\n",
    "                        'Final Destination': 'dest_final',\n",
    "                        'Coastal Region': 'coast_region',\n",
    "                        'Clearing District': 'clearing_district',\n",
    "                        'Place of Receipt': 'place_receipt',\n",
    "                        'Shipper': 'shipper_name',\n",
    "                        'Shipper Address': 'shipper_address',\n",
    "                        'Consignee': 'consignee_name',\n",
    "                        'Consignee Address': 'consignee_address',\n",
    "                        'Notify Party': 'notify_party1_name',\n",
    "                        'Notify Party Address': 'notify_party1_address',\n",
    "                        'Also Notify Party': 'notify_party2_name',\n",
    "                        'Also Notify Party Address': 'notify_party2_address',\n",
    "                        'Raw Commodity Description': 'commod_desc_raw',\n",
    "                        'Marks Container Number': 'container_id_marks',\n",
    "                        'Marks Description': 'marks_desc',\n",
    "                        'HS Code': 'hs_code',\n",
    "                        'JOC Code': 'joc_code',\n",
    "                        'Commodity Short Description': 'commod_short_desc',\n",
    "                        'Container Number': 'container_ids',\n",
    "                        'Carrier': 'carrier_name',\n",
    "                        'SCAC': 'carrier_scac',\n",
    "                        'Vessel Name': 'vessel_name',\n",
    "                        'Voyage Number': 'vessel_id',\n",
    "                        'Pre Carrier': 'precarrier',\n",
    "                        'IMO Number': 'imo_num',\n",
    "                        'Inbond Code': 'inbond_code',\n",
    "                        'Mode of Transport': 'transport_mode',\n",
    "                        'Bill of Lading Number': 'bol_id'}\n",
    "#define dtypes\n",
    "import_dtype_dict = {'Weight': 'float64',\n",
    "            'Weight Unit': 'category',\n",
    "            'Quantity': 'float64',\n",
    "            'Quantity Type': 'category',\n",
    "            'TEUs': 'float64',\n",
    "            'Estimated Value': 'float64',\n",
    "            'Arrival Date': 'int64',\n",
    "            'Container Piece Count': 'int64',\n",
    "            'Quantity of Commodity Short Description': 'object',\n",
    "            'Territory of Origin': 'category',\n",
    "            'Region of Origin': 'category',\n",
    "            'Port of Arrival Code': 'category',\n",
    "            'Port of Arrival': 'category',\n",
    "            'Port of Departure Code': 'category',\n",
    "            'Port of Departure': 'category',\n",
    "            'Final Destination': 'category',\n",
    "            'Coastal Region': 'category',\n",
    "            'Clearing District': 'category',\n",
    "            'Place of Receipt': 'category',\n",
    "            'Shipper': 'object',\n",
    "            'Shipper Address': 'object',\n",
    "            'Consignee': 'object',\n",
    "            'Consignee Address': 'object',\n",
    "            'Notify Party': 'object',\n",
    "            'Notify Party Address': 'object',\n",
    "            'Also Notify Party': 'object',\n",
    "            'Also Notify Party Address': 'object',\n",
    "            'Raw Commodity Description': 'object',\n",
    "            'Marks Container Number': 'object',\n",
    "            'Marks Description': 'object',\n",
    "            'HS Code': 'category',\n",
    "            'JOC Code': 'category',\n",
    "            'Commodity Short Description': 'object',\n",
    "            'Container Number': 'object',\n",
    "            'Carrier': 'category',\n",
    "            'SCAC': 'category',\n",
    "            'Vessel Name': 'object',\n",
    "            'Voyage Number': 'object',\n",
    "            'Pre Carrier': 'float64',\n",
    "            'IMO Number': 'float64',\n",
    "            'Inbond Code': 'float64',\n",
    "            'Mode of Transport': 'category',\n",
    "            'Bill of Lading Number': 'object'}\n",
    "#define category variable cols\n",
    "catcols = ['weight_unit', 'qty_type', 'origin_territory', 'origin_region', 'arrival_port_code', \n",
    "           'arrival_port_name', 'departure_port_code', 'departure_port_name', 'dest_final', 'coast_region', \n",
    "           'clearing_district', 'place_receipt', 'hs_code', 'joc_code', 'carrier_name', 'carrier_scac', \n",
    "           'transport_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CSV files...\n",
      " Files to process:  39 \n",
      "\n",
      "Extracting file  1 ...\n",
      "Extraction complete.\n",
      " Time: 30.30369281768799 sec \n",
      "\n",
      "Extracting file  2 ...\n",
      "Extraction complete.\n",
      " Time: 38.606818199157715 sec \n",
      "\n",
      "Extracting file  3 ...\n",
      "Extraction complete.\n",
      " Time: 20.177419900894165 sec \n",
      "\n",
      "Extracting file  4 ...\n",
      "Extraction complete.\n",
      " Time: 33.34604597091675 sec \n",
      "\n",
      "Extracting file  5 ...\n",
      "Extraction complete.\n",
      " Time: 34.10702681541443 sec \n",
      "\n",
      "Extracting file  6 ...\n",
      "Extraction complete.\n",
      " Time: 33.43861198425293 sec \n",
      "\n",
      "Extracting file  7 ...\n",
      "Extraction complete.\n",
      " Time: 20.76675009727478 sec \n",
      "\n",
      "Extracting file  8 ...\n",
      "Extraction complete.\n",
      " Time: 38.86877512931824 sec \n",
      "\n",
      "Extracting file  9 ...\n",
      "Extraction complete.\n",
      " Time: 47.7787709236145 sec \n",
      "\n",
      "Extracting file  10 ...\n",
      "Extraction complete.\n",
      " Time: 47.76598501205444 sec \n",
      "\n",
      "Extracting file  11 ...\n",
      "Extraction complete.\n",
      " Time: 36.88781189918518 sec \n",
      "\n",
      "Extracting file  12 ...\n",
      "Extraction complete.\n",
      " Time: 68.1502730846405 sec \n",
      "\n",
      "Extracting file  13 ...\n",
      "Extraction complete.\n",
      " Time: 59.50603485107422 sec \n",
      "\n",
      "Extracting file  14 ...\n",
      "Extraction complete.\n",
      " Time: 55.72740697860718 sec \n",
      "\n",
      "Extracting file  15 ...\n",
      "Extraction complete.\n",
      " Time: 112.34333205223083 sec \n",
      "\n",
      "Extracting file  16 ...\n",
      "Extraction complete.\n",
      " Time: 71.49107193946838 sec \n",
      "\n",
      "Extracting file  17 ...\n",
      "Extraction complete.\n",
      " Time: 101.57660007476807 sec \n",
      "\n",
      "Extracting file  18 ...\n",
      "Extraction complete.\n",
      " Time: 122.36245512962341 sec \n",
      "\n",
      "Extracting file  19 ...\n",
      "Extraction complete.\n",
      " Time: 124.83687400817871 sec \n",
      "\n",
      "Extracting file  20 ...\n",
      "Extraction complete.\n",
      " Time: 286.40643310546875 sec \n",
      "\n",
      "Extracting file  21 ...\n",
      "Extraction complete.\n",
      " Time: 212.7979221343994 sec \n",
      "\n",
      "Extracting file  22 ...\n",
      "Extraction complete.\n",
      " Time: 212.2327618598938 sec \n",
      "\n",
      "Extracting file  23 ...\n",
      "Extraction complete.\n",
      " Time: 261.81143975257874 sec \n",
      "\n",
      "Extracting file  24 ...\n",
      "Extraction complete.\n",
      " Time: 550.404541015625 sec \n",
      "\n",
      "Extracting file  25 ...\n",
      "Extraction complete.\n",
      " Time: 339.14352011680603 sec \n",
      "\n",
      "Extracting file  26 ...\n",
      "Extraction complete.\n",
      " Time: 1280.0292139053345 sec \n",
      "\n",
      "Extracting file  27 ...\n",
      "Extraction complete.\n",
      " Time: 438.097505569458 sec \n",
      "\n",
      "Extracting file  28 ...\n",
      "Extraction complete.\n",
      " Time: 418.41711807250977 sec \n",
      "\n",
      "Extracting file  29 ...\n",
      "Extraction complete.\n",
      " Time: 481.21947026252747 sec \n",
      "\n",
      "Extracting file  30 ...\n",
      "Extraction complete.\n",
      " Time: 919.8763341903687 sec \n",
      "\n",
      "Extracting file  31 ...\n",
      "Extraction complete.\n",
      " Time: 642.8634748458862 sec \n",
      "\n",
      "Extracting file  32 ...\n",
      "Extraction complete.\n",
      " Time: 695.3986430168152 sec \n",
      "\n",
      "Extracting file  33 ...\n",
      "Extraction complete.\n",
      " Time: 1586.8421077728271 sec \n",
      "\n",
      "Extracting file  34 ...\n",
      "Extraction complete.\n",
      " Time: 1804.94468998909 sec \n",
      "\n",
      "Extracting file  35 ...\n",
      "Extraction complete.\n",
      " Time: 4537.186676263809 sec \n",
      "\n",
      "Extracting file  36 ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Extracting CSV files...\\n', 'Files to process: ', len(datafiles), '\\n')\n",
    "\n",
    "#extract from csv to clean dataframes and concat\n",
    "for filename in datafiles:\n",
    "    start = time.time()\n",
    "    print('Extracting file ', filenumber, '...')\n",
    "    #read csv with appropriate dtypes\n",
    "    file_df = pd.read_csv(path+filename, dtype=import_dtype_dict)\n",
    "    #rename columns\n",
    "    file_df.rename(columns=import_colnames_dict, inplace=True)\n",
    "    #unpack strings to list objects\n",
    "    file_df.container_ids = file_df.container_ids.str.split()\n",
    "    file_df.commod_short_desc_qty = file_df.commod_short_desc_qty.str.split(pat=';')\n",
    "    file_df.commod_short_desc = file_df.commod_short_desc.str.split(pat=',')\n",
    "    #recast dates to datetime \n",
    "    file_df.date_arrival = pd.to_datetime(file_df.date_arrival.astype(str), format='%Y%m%d') \n",
    "    #concat to or create main imports df\n",
    "    if 'imports_df' in locals():\n",
    "        #create category unions and assign union to each df col\n",
    "        for col in catcols:\n",
    "            catunion = pd.api.types.union_categoricals([imports_df[col], file_df[col]])\n",
    "            imports_df[col] = pd.Categorical(imports_df[col], categories=catunion.categories)\n",
    "            file_df[col] = pd.Categorical(file_df[col], categories=catunion.categories)\n",
    "        #concat to main df\n",
    "        imports_df = pd.concat([imports_df, file_df])\n",
    "    else:\n",
    "        imports_df = file_df \n",
    "    del file_df\n",
    "    end = time.time()\n",
    "    print('Extraction complete.\\n', 'Time: {} sec \\n'.format(end-start))\n",
    "    filenumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect output \n",
    "display(imports_df.head())\n",
    "imports_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to parquet file\n",
    "imports_df.to_parquet('data/piers_imports.parquet', index=False, engine='fastparquet') #requires fastparquet dependency  \n",
    "\n",
    "#delete imports df\n",
    "del imports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_df = pd.read_parquet('data/piers_imports.parquet', engine='fastparquet')\n",
    "imports_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
