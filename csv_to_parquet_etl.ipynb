{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "#ini Dask client\n",
    "cluster = LocalCluster(n_workers=10)\n",
    "client = Client(cluster)\n",
    "\n",
    "#display settings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "- read csvs\n",
    "    - set datatypes and column names during read\n",
    "- \n",
    "- concat dataframes\n",
    "    - use union categoricals to preserve categories\n",
    "- drop duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "path = 'data/raw/'\n",
    "#get list of data files, ignoring any hidden files in directory \n",
    "datafiles = [file for file in os.listdir(path) if not file.startswith('.')]\n",
    "#init filenumber\n",
    "filenumber = 1\n",
    "#define new col names\n",
    "import_colnames_dict = {'Weight': 'weight',\n",
    "                        'Weight Unit': 'weight_unit',\n",
    "                        'Quantity': 'qty',\n",
    "                        'Quantity Type': 'qty_type',\n",
    "                        'TEUs': 'teus',\n",
    "                        'Estimated Value': 'value_est',\n",
    "                        'Arrival Date': 'date_arrival',\n",
    "                        'Container Piece Count': 'container_piece_count',\n",
    "                        'Quantity of Commodity Short Description': 'commod_short_desc_qty',\n",
    "                        'Territory of Origin': 'origin_territory',\n",
    "                        'Region of Origin': 'origin_region',\n",
    "                        'Port of Arrival Code': 'arrival_port_code',\n",
    "                        'Port of Arrival': 'arrival_port_name',\n",
    "                        'Port of Departure Code': 'departure_port_code',\n",
    "                        'Port of Departure': 'departure_port_name',\n",
    "                        'Final Destination': 'dest_final',\n",
    "                        'Coastal Region': 'coast_region',\n",
    "                        'Clearing District': 'clearing_district',\n",
    "                        'Place of Receipt': 'place_receipt',\n",
    "                        'Shipper': 'shipper_name',\n",
    "                        'Shipper Address': 'shipper_address',\n",
    "                        'Consignee': 'consignee_name',\n",
    "                        'Consignee Address': 'consignee_address',\n",
    "                        'Notify Party': 'notify_party1_name',\n",
    "                        'Notify Party Address': 'notify_party1_address',\n",
    "                        'Also Notify Party': 'notify_party2_name',\n",
    "                        'Also Notify Party Address': 'notify_party2_address',\n",
    "                        'Raw Commodity Description': 'commod_desc_raw',\n",
    "                        'Marks Container Number': 'container_id_marks',\n",
    "                        'Marks Description': 'marks_desc',\n",
    "                        'HS Code': 'hs_code',\n",
    "                        'JOC Code': 'joc_code',\n",
    "                        'Commodity Short Description': 'commod_short_desc',\n",
    "                        'Container Number': 'container_ids',\n",
    "                        'Carrier': 'carrier_name',\n",
    "                        'SCAC': 'carrier_scac',\n",
    "                        'Vessel Name': 'vessel_name',\n",
    "                        'Voyage Number': 'vessel_id',\n",
    "                        'Pre Carrier': 'precarrier',\n",
    "                        'IMO Number': 'imo_num',\n",
    "                        'Inbond Code': 'inbond_code',\n",
    "                        'Mode of Transport': 'transport_mode',\n",
    "                        'Bill of Lading Number': 'bol_id'}\n",
    "#define dtypes\n",
    "import_dtype_dict = {'Weight': 'float64',\n",
    "            'Weight Unit': 'category',\n",
    "            'Quantity': 'float64',\n",
    "            'Quantity Type': 'category',\n",
    "            'TEUs': 'float64',\n",
    "            'Estimated Value': 'float64',\n",
    "            'Arrival Date': 'int64',\n",
    "            'Container Piece Count': 'int64',\n",
    "            'Quantity of Commodity Short Description': 'object',\n",
    "            'Territory of Origin': 'category',\n",
    "            'Region of Origin': 'category',\n",
    "            'Port of Arrival Code': 'category',\n",
    "            'Port of Arrival': 'category',\n",
    "            'Port of Departure Code': 'category',\n",
    "            'Port of Departure': 'category',\n",
    "            'Final Destination': 'category',\n",
    "            'Coastal Region': 'category',\n",
    "            'Clearing District': 'category',\n",
    "            'Place of Receipt': 'category',\n",
    "            'Shipper': 'object',\n",
    "            'Shipper Address': 'object',\n",
    "            'Consignee': 'object',\n",
    "            'Consignee Address': 'object',\n",
    "            'Notify Party': 'object',\n",
    "            'Notify Party Address': 'object',\n",
    "            'Also Notify Party': 'object',\n",
    "            'Also Notify Party Address': 'object',\n",
    "            'Raw Commodity Description': 'object',\n",
    "            'Marks Container Number': 'object',\n",
    "            'Marks Description': 'object',\n",
    "            'HS Code': 'category',\n",
    "            'JOC Code': 'category',\n",
    "            'Commodity Short Description': 'object',\n",
    "            'Container Number': 'object',\n",
    "            'Carrier': 'category',\n",
    "            'SCAC': 'category',\n",
    "            'Vessel Name': 'object',\n",
    "            'Voyage Number': 'object',\n",
    "            'Pre Carrier': 'float64',\n",
    "            'IMO Number': 'float64',\n",
    "            'Inbond Code': 'float64',\n",
    "            'Mode of Transport': 'category',\n",
    "            'Bill of Lading Number': 'object'}\n",
    "#define category variable cols\n",
    "catcols = ['weight_unit', 'qty_type', 'origin_territory', 'origin_region', 'arrival_port_code', \n",
    "           'arrival_port_name', 'departure_port_code', 'departure_port_name', 'dest_final', 'coast_region', \n",
    "           'clearing_district', 'place_receipt', 'hs_code', 'joc_code', 'carrier_name', 'carrier_scac', \n",
    "           'transport_mode']\n",
    "#get col names for reordering\n",
    "import_colnames = list(import_colnames_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CSV files...\n",
      " Files to process:  39 \n",
      "\n",
      "Extracting file 1...\n",
      "File extracted. That took 15.014738082885742 sec.\n",
      "Saving file 1 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 1: 23.72644305229187 sec \n",
      "\n",
      "Extracting file 2...\n",
      "File extracted. That took 63.04529690742493 sec.\n",
      "Saving file 2 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 2: 73.83171582221985 sec \n",
      "\n",
      "Extracting file 3...\n",
      "File extracted. That took 19.983909130096436 sec.\n",
      "Saving file 3 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 3: 25.05823516845703 sec \n",
      "\n",
      "Extracting file 4...\n",
      "File extracted. That took 35.92933797836304 sec.\n",
      "Saving file 4 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 4: 44.57157897949219 sec \n",
      "\n",
      "Extracting file 5...\n",
      "File extracted. That took 36.683330059051514 sec.\n",
      "Saving file 5 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 5: 46.062987089157104 sec \n",
      "\n",
      "Extracting file 6...\n",
      "File extracted. That took 34.82046389579773 sec.\n",
      "Saving file 6 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 6: 43.402889013290405 sec \n",
      "\n",
      "Extracting file 7...\n",
      "File extracted. That took 18.734493255615234 sec.\n",
      "Saving file 7 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 7: 23.560145139694214 sec \n",
      "\n",
      "Extracting file 8...\n",
      "File extracted. That took 31.900590181350708 sec.\n",
      "Saving file 8 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 8: 40.37475824356079 sec \n",
      "\n",
      "Extracting file 9...\n",
      "File extracted. That took 53.03805112838745 sec.\n",
      "Saving file 9 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 9: 65.56257009506226 sec \n",
      "\n",
      "Extracting file 10...\n",
      "File extracted. That took 42.837631940841675 sec.\n",
      "Saving file 10 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 10: 51.984416007995605 sec \n",
      "\n",
      "Extracting file 11...\n",
      "File extracted. That took 29.582192182540894 sec.\n",
      "Saving file 11 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 11: 37.125097036361694 sec \n",
      "\n",
      "Extracting file 12...\n",
      "File extracted. That took 56.22887086868286 sec.\n",
      "Saving file 12 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 12: 66.92535400390625 sec \n",
      "\n",
      "Extracting file 13...\n",
      "File extracted. That took 35.17935800552368 sec.\n",
      "Saving file 13 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 13: 44.220422983169556 sec \n",
      "\n",
      "Extracting file 14...\n",
      "File extracted. That took 24.073691844940186 sec.\n",
      "Saving file 14 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 14: 30.1952121257782 sec \n",
      "\n",
      "Extracting file 15...\n",
      "File extracted. That took 29.837707996368408 sec.\n",
      "Saving file 15 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 15: 37.05813407897949 sec \n",
      "\n",
      "Extracting file 16...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 15:02:17,701 - distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted. That took 76.64041018486023 sec.\n",
      "Saving file 16 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 16: 82.74497318267822 sec \n",
      "\n",
      "Extracting file 17...\n",
      "File extracted. That took 36.422752141952515 sec.\n",
      "Saving file 17 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 17: 45.33340811729431 sec \n",
      "\n",
      "Extracting file 18...\n",
      "File extracted. That took 29.241694927215576 sec.\n",
      "Saving file 18 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 18: 36.390482902526855 sec \n",
      "\n",
      "Extracting file 19...\n",
      "File extracted. That took 21.168065071105957 sec.\n",
      "Saving file 19 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 19: 26.004690885543823 sec \n",
      "\n",
      "Extracting file 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 15:05:54,961 - distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted. That took 106.75309801101685 sec.\n",
      "Saving file 20 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 20: 113.77377104759216 sec \n",
      "\n",
      "Extracting file 21...\n",
      "File extracted. That took 34.01321196556091 sec.\n",
      "Saving file 21 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 21: 42.328327894210815 sec \n",
      "\n",
      "Extracting file 22...\n",
      "File extracted. That took 16.641629934310913 sec.\n",
      "Saving file 22 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 22: 20.52099609375 sec \n",
      "\n",
      "Extracting file 23...\n",
      "File extracted. That took 48.01070284843445 sec.\n",
      "Saving file 23 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 23: 59.97862887382507 sec \n",
      "\n",
      "Extracting file 24...\n",
      "File extracted. That took 52.51041293144226 sec.\n",
      "Saving file 24 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 24: 64.71740698814392 sec \n",
      "\n",
      "Extracting file 25...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 15:11:24,616 - distributed.utils_perf - WARNING - full garbage collections took 20% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted. That took 137.00891494750977 sec.\n",
      "Saving file 25 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 25: 145.89261603355408 sec \n",
      "\n",
      "Extracting file 26...\n",
      "File extracted. That took 41.684616804122925 sec.\n",
      "Saving file 26 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 26: 51.329452991485596 sec \n",
      "\n",
      "Extracting file 27...\n",
      "File extracted. That took 33.806188106536865 sec.\n",
      "Saving file 27 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 27: 40.7286262512207 sec \n",
      "\n",
      "Extracting file 28...\n",
      "File extracted. That took 24.715368032455444 sec.\n",
      "Saving file 28 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 28: 30.003836154937744 sec \n",
      "\n",
      "Extracting file 29...\n",
      "File extracted. That took 41.24799990653992 sec.\n",
      "Saving file 29 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 29: 50.97440505027771 sec \n",
      "\n",
      "Extracting file 30...\n",
      "File extracted. That took 35.29223322868347 sec.\n",
      "Saving file 30 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 30: 44.899818897247314 sec \n",
      "\n",
      "Extracting file 31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 15:18:24,462 - distributed.utils_perf - WARNING - full garbage collections took 22% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted. That took 189.98041200637817 sec.\n",
      "Saving file 31 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 31: 197.5816900730133 sec \n",
      "\n",
      "Extracting file 32...\n",
      "File extracted. That took 38.540515184402466 sec.\n",
      "Saving file 32 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 32: 47.92301416397095 sec \n",
      "\n",
      "Extracting file 33...\n",
      "File extracted. That took 22.093156814575195 sec.\n",
      "Saving file 33 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 33: 27.177011966705322 sec \n",
      "\n",
      "Extracting file 34...\n",
      "File extracted. That took 28.94852089881897 sec.\n",
      "Saving file 34 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 34: 35.03355002403259 sec \n",
      "\n",
      "Extracting file 35...\n",
      "File extracted. That took 38.395867109298706 sec.\n",
      "Saving file 35 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 35: 47.65315389633179 sec \n",
      "\n",
      "Extracting file 36...\n",
      "File extracted. That took 25.810106992721558 sec.\n",
      "Saving file 36 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 36: 31.064847946166992 sec \n",
      "\n",
      "Extracting file 37...\n",
      "File extracted. That took 35.70425605773926 sec.\n",
      "Saving file 37 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 37: 44.289392948150635 sec \n",
      "\n",
      "Extracting file 38...\n",
      "File extracted. That took 35.90897583961487 sec.\n",
      "Saving file 38 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 38: 44.64583873748779 sec \n",
      "\n",
      "Extracting file 39...\n",
      "File extracted. That took 23.428040027618408 sec.\n",
      "Saving file 39 to parquet...\n",
      "File ETL complete.\n",
      " Total time for file 39: 28.321582794189453 sec \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Extracting CSV files...\\n', 'Files to process: ', len(datafiles), '\\n')\n",
    "\n",
    "for file in datafiles:\n",
    "    #extract from csv to clean dataframes and concat\n",
    "    start = time.time()\n",
    "    print('Extracting file {}...'.format(filenumber))\n",
    "    #read csv with appropriate dtypes\n",
    "    file_df = dd.read_csv(path+file, dtype=import_dtype_dict, assume_missing=True, sample=1000)\n",
    "    \n",
    "    #rename columns\n",
    "    file_df = file_df.compute().rename(columns=import_colnames_dict)\n",
    "    #unpack strings to list objects\n",
    "    file_df.container_ids = file_df.container_ids.str.split()\n",
    "    file_df.commod_short_desc_qty = file_df.commod_short_desc_qty.str.split(pat=';')\n",
    "    file_df.commod_short_desc = file_df.commod_short_desc.str.split(pat=',')\n",
    "    #recast dates to datetime \n",
    "    file_df.date_arrival = pd.to_datetime(file_df.date_arrival.astype(str), format='%Y%m%d')\n",
    "    #reorder columns\n",
    "    file_df = file_df[import_colnames]\n",
    "    #concat to imports_df\n",
    "    if 'imports_df' in locals():\n",
    "        imports_df = dd.concat([imports_df, file_df])\n",
    "    else: \n",
    "        imports_df = file_df\n",
    "    #save file_df\n",
    "    extract = time.time()\n",
    "    print('File extracted. That took {} sec.'.format(extract-start))\n",
    "    print('Saving file {} to parquet...'.format(filenumber))\n",
    "    file_df.to_parquet('data/clean_parquet/'+ file[:-3] + 'parquet')\n",
    "    del file_df\n",
    "    end = time.time()\n",
    "    print('File ETL complete.\\n', 'Total time for file {}: {} sec \\n'.format(filenumber, end-start))\n",
    "    filenumber += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#inspect imports_df\n",
    "imports_df.compute().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Dask client and cluster\n",
    "#client.close()\n",
    "#cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
