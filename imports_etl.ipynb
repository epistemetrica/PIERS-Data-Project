{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIERS Imports ETL\n",
    "\n",
    "This notebook extracts Bill of Lading data from csv files downloaded from S&P Global's PIERS BoL database. Transformations are limited here to setting appropriate datatypes for storage, adding year month and direction columns, and dropping duplicated rows. The data is then saved in .parquet format files by arrival year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import polars as pl #v0.20.7\n",
    "\n",
    "#enable string cache for polars categoricals\n",
    "pl.enable_string_cache()\n",
    "\n",
    "#define dtypes\n",
    "imports_dtypes = {'Weight': pl.Float64,\n",
    "            'Weight Unit': pl.Categorical,\n",
    "            'Quantity': pl.Float64,\n",
    "            'Quantity Type': pl.Categorical,\n",
    "            'TEUs': pl.Float64,\n",
    "            'Estimated Value': pl.Float64,\n",
    "            'Arrival Date': pl.Utf8,\n",
    "            'Container Piece Count': pl.Int32,\n",
    "            'Quantity of Commodity Short Description': pl.Utf8,\n",
    "            'Territory of Origin': pl.Categorical,\n",
    "            'Region of Origin': pl.Categorical,\n",
    "            'Port of Arrival Code': pl.Categorical,\n",
    "            'Port of Arrival': pl.Categorical,\n",
    "            'Port of Departure Code': pl.Categorical,\n",
    "            'Port of Departure': pl.Categorical,\n",
    "            'Final Destination': pl.Categorical,\n",
    "            'Coastal Region': pl.Categorical,\n",
    "            'Clearing District': pl.Categorical,\n",
    "            'Place of Receipt': pl.Categorical,\n",
    "            'Shipper': pl.Utf8,\n",
    "            'Shipper Address': pl.Utf8,\n",
    "            'Consignee': pl.Utf8,\n",
    "            'Consignee Address': pl.Utf8,\n",
    "            'Notify Party': pl.Utf8,\n",
    "            'Notify Party Address': pl.Utf8,\n",
    "            'Also Notify Party': pl.Utf8,\n",
    "            'Also Notify Party Address': pl.Utf8,\n",
    "            'Raw Commodity Description': pl.Utf8,\n",
    "            'Marks Container Number': pl.Utf8,\n",
    "            'Marks Description': pl.Utf8,\n",
    "            'HS Code': pl.Utf8,\n",
    "            'JOC Code': pl.Utf8,\n",
    "            'Commodity Short Description': pl.Utf8,\n",
    "            'Container Number': pl.Utf8,\n",
    "            'Carrier': pl.Categorical,\n",
    "            'SCAC': pl.Categorical,\n",
    "            'Vessel Name': pl.Utf8,\n",
    "            'Voyage Number': pl.Utf8,\n",
    "            'Pre Carrier': pl.Float64,\n",
    "            'IMO Number': pl.Int32,\n",
    "            'Inbond Code': pl.Float64,\n",
    "            'Mode of Transport': pl.Categorical,\n",
    "            'Bill of Lading Number': pl.Utf8}\n",
    "\n",
    "#define pythonic column names \n",
    "import_colnames_dict = {'Weight': 'weight',\n",
    "            'Weight Unit': 'weight_unit',\n",
    "            'Quantity': 'qty',\n",
    "            'Quantity Type': 'qty_type',\n",
    "            'TEUs': 'teus',\n",
    "            'Estimated Value': 'value_est',\n",
    "            'Arrival Date': 'date',\n",
    "            'Container Piece Count': 'container_piece_count',\n",
    "            'Quantity of Commodity Short Description': 'commod_short_desc_qty',\n",
    "            'Territory of Origin': 'origin_territory',\n",
    "            'Region of Origin': 'origin_region',\n",
    "            'Port of Arrival Code': 'arrival_port_code',\n",
    "            'Port of Arrival': 'arrival_port_name',\n",
    "            'Port of Departure Code': 'departure_port_code',\n",
    "            'Port of Departure': 'departure_port_name',\n",
    "            'Final Destination': 'dest_final',\n",
    "            'Coastal Region': 'coast_region',\n",
    "            'Clearing District': 'clearing_district',\n",
    "            'Place of Receipt': 'place_receipt',\n",
    "            'Shipper': 'shipper_name',\n",
    "            'Shipper Address': 'shipper_address',\n",
    "            'Consignee': 'consignee_name',\n",
    "            'Consignee Address': 'consignee_address',\n",
    "            'Notify Party': 'notify_party1_name',\n",
    "            'Notify Party Address': 'notify_party1_address',\n",
    "            'Also Notify Party': 'notify_party2_name',\n",
    "            'Also Notify Party Address': 'notify_party2_address',\n",
    "            'Raw Commodity Description': 'commod_desc_raw',\n",
    "            'Marks Container Number': 'container_id_marks',\n",
    "            'Marks Description': 'marks_desc',\n",
    "            'HS Code': 'hs_code',\n",
    "            'JOC Code': 'joc_code',\n",
    "            'Commodity Short Description': 'commod_short_desc',\n",
    "            'Container Number': 'container_ids',\n",
    "            'Carrier': 'carrier_name',\n",
    "            'SCAC': 'carrier_scac',\n",
    "            'Vessel Name': 'vessel_name',\n",
    "            'Voyage Number': 'voyage_number',\n",
    "            'Pre Carrier': 'precarrier',\n",
    "            'IMO Number': 'vessel_id',\n",
    "            'Inbond Code': 'inbond_code',\n",
    "            'Mode of Transport': 'transport_mode',\n",
    "            'Bill of Lading Number': 'bol_number'}\n",
    "\n",
    "#define schema\n",
    "imports_schema = {'weight': pl.Float64,\n",
    "                'weight_unit': pl.Categorical,\n",
    "                'qty': pl.Float64,\n",
    "                'qty_type': pl.Categorical,\n",
    "                'teus': pl.Float64,\n",
    "                'value_est': pl.Float64,\n",
    "                'date': pl.Utf8,\n",
    "                'container_piece_count': pl.Int32,\n",
    "                'commod_short_desc_qty': pl.Utf8,\n",
    "                'origin_territory': pl.Categorical,\n",
    "                'origin_region': pl.Categorical,\n",
    "                'arrival_port_code': pl.Categorical,\n",
    "                'arrival_port_name': pl.Categorical,\n",
    "                'departure_port_code': pl.Categorical,\n",
    "                'departure_port_name': pl.Categorical,\n",
    "                'dest_final': pl.Categorical,\n",
    "                'coast_region': pl.Categorical,\n",
    "                'clearing_district': pl.Categorical,\n",
    "                'place_receipt': pl.Categorical,\n",
    "                'shipper_name': pl.Utf8,\n",
    "                'shipper_address': pl.Utf8,\n",
    "                'consignee_name': pl.Utf8,\n",
    "                'consignee_address': pl.Utf8,\n",
    "                'notify_party1_name': pl.Utf8,\n",
    "                'notify_party1_address': pl.Utf8,\n",
    "                'notify_party2_name': pl.Utf8,\n",
    "                'notify_party2_address': pl.Utf8,\n",
    "                'commod_desc_raw': pl.Utf8,\n",
    "                'container_id_marks': pl.Utf8,\n",
    "                'marks_desc': pl.Utf8,\n",
    "                'hs_code': pl.Utf8,\n",
    "                'joc_code': pl.Utf8,\n",
    "                'commod_short_desc': pl.Utf8,\n",
    "                'container_ids': pl.Utf8,\n",
    "                'carrier_name': pl.Categorical,\n",
    "                'carrier_scac': pl.Categorical,\n",
    "                'vessel_name': pl.Utf8,\n",
    "                'voyage_number': pl.Utf8,\n",
    "                'precarrier': pl.Float64,\n",
    "                'vessel_id': pl.Int32,\n",
    "                'inbond_code': pl.Float64,\n",
    "                'transport_mode': pl.Categorical,\n",
    "                'bol_number': pl.Utf8}\n",
    "\n",
    "#define years\n",
    "years = pl.arange(2005,2024, eager=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting observations from 2005...\n",
      "2005 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2006...\n",
      "2006 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2007...\n",
      "2007 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2008...\n",
      "2008 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2009...\n",
      "2009 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2010...\n",
      "2010 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2011...\n",
      "2011 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2012...\n",
      "2012 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2013...\n",
      "2013 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2014...\n",
      "2014 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2015...\n",
      "2015 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2016...\n",
      "2016 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2017...\n",
      "2017 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2018...\n",
      "2018 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2019...\n",
      "2019 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2020...\n",
      "2020 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2021...\n",
      "2021 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2022...\n",
      "2022 pldf collected. \n",
      "Writing to parquet...\n",
      "Collecting observations from 2023...\n",
      "2023 pldf collected. \n",
      "Writing to parquet...\n",
      "\n",
      "Imports ETL complete.\n"
     ]
    }
   ],
   "source": [
    "#ETL\n",
    "for year in years:\n",
    "    print('Collecting observations from '+str(year)+'...')\n",
    "    df = (\n",
    "        #scan csvs\n",
    "        pl.scan_csv('data/raw_csv/imports/*.csv', dtypes=imports_dtypes)\n",
    "        #rename columns\n",
    "        .rename(import_colnames_dict)\n",
    "        #reorder columns\n",
    "        .select(import_colnames_dict.values())\n",
    "        #filter by year\n",
    "        .filter(pl.col('date').str.starts_with(str(year)))\n",
    "        #collect\n",
    "        .collect()\n",
    "    )\n",
    "    df = (\n",
    "        #cast entire df to string\n",
    "        df.cast(pl.Utf8)\n",
    "        #strip whitespace and replace empty str with null\n",
    "        .with_columns(pl.all().str.strip_chars().replace('',None))\n",
    "        #recast appropriately\n",
    "        .cast(imports_schema)\n",
    "        #drop duplicates\n",
    "        .unique()\n",
    "        #cast date col to datetime\n",
    "        .with_columns(pl.col('date').str.to_datetime('%Y%m%d'))\n",
    "        .with_columns(\n",
    "            #create direction column\n",
    "            pl.lit('import').cast(pl.Categorical).alias('direction'),\n",
    "            #create bol_id\n",
    "            (pl.col('carrier_scac').fill_null('')+'_'+pl.col('bol_number')).alias('bol_id'),\n",
    "            #extract year\n",
    "            pl.col('date').dt.year().alias('year'),\n",
    "            #extract month (e.g., '202304')\n",
    "            pl.col('date').dt.strftime('%Y%m').alias('month'),\n",
    "            #create lane_id\n",
    "            (pl.col('departure_port_code').cast(pl.Utf8)+'_'+pl.col('arrival_port_code').cast(pl.Utf8))\n",
    "            .cast(pl.Categorical)\n",
    "            .alias('lane_id'),\n",
    "            #convert zero volume values to null\n",
    "            pl.col('teus').replace(0,None),\n",
    "            pl.col('weight').replace(0,None),\n",
    "            pl.col('qty').replace(0,None)\n",
    "        )\n",
    "    )\n",
    "    print(str(year)+' dataframe collected. \\nWriting to parquet...')\n",
    "    #write file to parquet\n",
    "    df.write_parquet(file='data/raw_parquet/imports/piers_imports_'+str(year)+'.parquet')\n",
    "    del df\n",
    "\n",
    "print('\\nImports ETL complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close string cache\n",
    "pl.disable_string_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
